---
title: 用余弦定理+大数据找到心仪的对象
date: 2020-03-23 22:16:11
tags:
---

![cosin](/images/cover/cosin.jpg)
## 前言

余弦定理和找对象似乎是两件八杆子打不着的事，但是它们却有着类似于余弦定理和Google的新闻自动分类一样的紧密联系。具体来说，找对象也可以和做Google的新闻自动分类一样，找到最契合的另一半。

<!-- more -->

## 原理

找对象之前，先来看看文章自动分类的原理，我们做文章自动分类时，第一步是从分词入手

### 第一步，分词

这里使用了一个Node.js比较成熟的分词库，底层算法是基于c++做的实现，性能不错。

参见 [/index.js#L88](https://github.com/tkvern/nodejs-text-similarity/blob/master/index.js#L88)

```javascript
  /**
   * 简单分词
   * @param {String} text 文本
   * @returns {Array}
   */
  segment(text) {
    if (!text) return []
    return nodejieba.cut(text)
  }
```



### 第二步， 列出所有词

分词之后我们将得到所有的词

参见 [/index.js#L11](https://github.com/tkvern/nodejs-text-similarity/blob/master/index.js#L11)

```javascript
  /**
   * 文本相似度查询
   * @param {String} textA 文本A
   * @param {String} textB 文本B
   */
  constructor(textA, textB) {
    textA = "" + textA
    textB = "" + textB
    this.segmentWordsA = this.segment(textA)
    this.segmentWordsB = this.segment(textB)
  }
```



### 第三步，统计词频率

当我们拿到所有词的数组后，还需要进行词频统计，`EXCLUDE_WORDS_ARRAY`这个是我们排出的一些语气助词。

参见 [/index.js#L43](https://github.com/tkvern/nodejs-text-similarity/blob/master/index.js#L43)

```javascript
  /**
   * 分析两段文本
   */
  analyse() {
    // 分析A片段
    this.segmentWordsA.forEach(element => {
      if (!this.EXCLUDE_WORDS_ARRAY.includes(element)) {
        if (!this.distributionWordsArray.hasOwnProperty(element)) {
          this.distributionWordsArray[element] = [1, 0]
        } else {
          this.distributionWordsArray[element][0] += 1
        }
      }
    })

    // 分析B片段
    this.segmentWordsB.forEach(element => {
      if (!this.EXCLUDE_WORDS_ARRAY.includes(element)) {
        if (!this.distributionWordsArray.hasOwnProperty(element)) {
          this.distributionWordsArray[element] = [0, 1]
        } else {
          this.distributionWordsArray[element][1] += 1
        }
      }
    })
  }
```

### 第四步，根据词频向量计算相似程度

```
句子A： "太阳刚升起夕阳已落下"
句子B： "我在马路边夕阳已落下"
```



通过计算，我们会得到这样一个词频数组

![向量](/images/cosin/131584975100.jpg)

结合余弦定理:

![夹角](/images/cosin/bg2013032002.png)

对于n维向量的计算如下:

![n维计算](/images/cosin/bg2013032007.png)

而计算出来的余弦值越接近1，则表明夹角越接近0度，也就是两个向量越相似。

参见[/index.js#71]((https://github.com/tkvern/nodejs-text-similarity/blob/master/index.js#L43)

```javascript
  /**
   * 处理相似度
   * @returns {Number}
   */
  similarity() {
    let [sum, sumWordsA, sumWordsB] = [0, 0, 0]
    for (const element in this.distributionWordsArray) {
      const wordsA = this.distributionWordsArray[element][0]
      const wordsB = this.distributionWordsArray[element][1]
      sum += (wordsA * wordsB)
      sumWordsA += Math.pow(wordsA, 2)
      sumWordsB += Math.pow(wordsB, 2)
    }
    return sum / Math.sqrt(sumWordsA * sumWordsB)
  }
```



## 找对象

和做文章自动分类一样



### 第一步，基本信息、个性、兴趣爱好分析

和分词原理类似，我们要将每个人的物理数据数字化，并按照不同的维度拆分



### 第二步，列出所有数字化后的数据

分析之后，我们将得到数字化的人物画像。



### 第三步，参数统计

对数字化后的每一项数据，进行统计



### 第四步，计算相似程度

这里用到的计算方法和词频统计一样，而拓展一些的地方是，可以给某些参数增加权重。

这样就可以结合你的个人状况，找到最适合你的对象了。



## 大数据

你应该已经注意到了，我们做文章自动分类的前提，是有足够多的文章数据

所以，用余弦定理+大数据找到心仪的对象，也需要有足够多的数字化数据。

而一切的前提，是要有足够多的对象数据，所以要先挖掘下数据吧。

![happy](/images/cosin/happy.jpeg)



## Plan

我有个帮你找对象的计划，如果你有找对象的需求，可以提交到我的系统里面来哦～



## 项目地址

文中代码仓库请访问 https://github.com/tkvern/nodejs-text-similarity

